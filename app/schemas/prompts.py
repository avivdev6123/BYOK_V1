"""
Pydantic schemas for Prompt API (Milestone 1 + Milestone 2).

These classes define:
- What the user sends (request)
- What the API returns (response)
They also automatically generate Swagger documentation.

Milestone 2 adds:
- PromptProfile: the JSON profile generated by an LLM (or stub)
- Updated response schemas that include prompt_profile_json
"""

from datetime import datetime  # used for created_at timestamps in responses
from typing import Literal, Optional  # used to define strict allowed values + optional fields

from pydantic import BaseModel, Field  # BaseModel for schemas + Field for validations


# ----------------------------
# Milestone 2: JSON profile types
# ----------------------------

# task_type must be one of these fixed values (very testable)
TaskType = Literal["web_search", "text_generation", "coding", "summarization", "extraction"]

# output_format must be one of these fixed values
OutputFormat = Literal["text", "json"]

# urgency must be one of these fixed values
Urgency = Literal["fast", "normal"]


class PromptProfile(BaseModel):
    """
    Milestone 2 JSON profile schema.

    This is the structured JSON that the profiler returns from ONE LLM call.
    We keep it strict so we can validate it easily and catch bad outputs.
    """

    # What kind of task the prompt looks like
    task_type: TaskType

    # Whether the prompt needs web access (RAG/web tool) to answer properly
    needs_web: bool

    # Whether the prompt needs code execution / coding reasoning
    needs_code: bool

    # Requested output format (plain text or JSON)
    output_format: OutputFormat

    # How urgent the prompt feels (fast response vs normal)
    urgency: Urgency

    # Confidence score between 0 and 1
    confidence: float = Field(ge=0.0, le=1.0)


# ----------------------------
# Milestone 1: Request schema
# ----------------------------

class PromptCreateRequest(BaseModel):
    """
    Request body when a user submits a prompt.

    Milestone 1 used 'prompt' as the field name.
    We'll keep it so we don't break existing clients.
    """

    # Username of the caller (MVP identity)
    username: str = Field(default="demo", min_length=1)

    # The actual prompt text (Milestone 1 name: "prompt")
    prompt: str = Field(min_length=1)


# ----------------------------
# Milestone 1: Basic create response
# (Keep this for backward compatibility)
# ----------------------------

class PromptCreateResponse(BaseModel):
    """
    Response after storing a prompt (Milestone 1).
    """

    # Database ID of the stored prompt
    prompt_id: int

    # Simple status indicator
    status: str = "stored"


# ----------------------------
# Milestone 2: Enhanced create response
# ----------------------------

class PromptCreateWithProfileResponse(BaseModel):
    """
    Response after storing a prompt AND extracting a JSON profile (Milestone 2).

    This is the response we will use for POST /v1/prompts in Milestone 2.
    """

    # Database ID of the stored prompt
    prompt_id: int

    # Username that submitted the prompt
    username: str

    # Original prompt text
    raw_prompt: str

    # The extracted JSON profile (output of the profiler step)
    prompt_profile_json: PromptProfile


# ----------------------------
# Milestone 1: Read response
# ----------------------------

class PromptReadResponse(BaseModel):
    """
    Response when fetching a stored prompt (Milestone 1).
    """

    prompt_id: int
    username: str
    raw_prompt: str
    created_at: datetime


# ----------------------------
# Milestone 2: Read response with profile
# ----------------------------

class PromptReadWithProfileResponse(BaseModel):
    """
    Response when fetching a stored prompt INCLUDING the JSON profile (Milestone 2).
    """

    prompt_id: int
    username: str
    raw_prompt: str
    created_at: datetime

    # Optional in case older rows exist without a profile
    prompt_profile_json: Optional[PromptProfile] = None